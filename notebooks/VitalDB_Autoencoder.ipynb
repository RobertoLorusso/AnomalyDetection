{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO-DO/BUGS/Considerations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUGS\n",
    "\n",
    "- When introducing the ECG as feature, the prediction gives nan values. Need to try to implement a single feature LSTM autoencoder on the ECG and see if the behaviour is different\n",
    "\n",
    "### TO-DO\n",
    "\n",
    "- Threshold for anomaly = mean of the reconstruction error for healthy patients. Above this threshold we can detyect an anomaly\n",
    "\n",
    "- Covariance matrix\n",
    "\n",
    "### Considerations\n",
    "\n",
    "- L'errore di ricostruzione è minore usando la normalizzazione minmax, probabilmente perchè i dati non hanno una distribuzione gaussiana"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vitaldb\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_healthy_API(type='a',n_cases=None):\n",
    "    caseids_all = vitaldb.find_cases(['ECG_II','ART_DBP','ART_SBP','BT','HR','RR']) # find ids of patient with this parameters\n",
    "    # Load dataset\n",
    "    df = pd.read_csv('https://api.vitaldb.net/cases')\n",
    "    df = df[df['asa'] < 3]\n",
    "\n",
    "    caseids_unhealthy = df['caseid'].to_numpy() \n",
    "    caseids = [el for el in caseids_all if el in caseids_unhealthy]\n",
    "\n",
    "    if(n_cases is None):\n",
    "        n_cases = len(caseids)\n",
    "\n",
    "    ecg = []\n",
    "    dbp = []\n",
    "    sbp = []\n",
    "    bt  = []\n",
    "    hr  = []\n",
    "    rr  = []\n",
    "\n",
    "    if(type in ('a','n','w')):\n",
    "\n",
    "        if(type in ('a','n')):\n",
    "\n",
    "            # load all the patients data \n",
    "            for i in range(0,n_cases): # Select only five patient for testing purpose; then len(caseids)\n",
    "                try:\n",
    "                    vals = vitaldb.load_case(caseids[i], ['ART_DBP','ART_SBP','BT','HR','RR'])\n",
    "                    dbp.append(vals[:,0])\n",
    "                    sbp.append(vals[:,1])\n",
    "                    bt.append(vals[:,2])\n",
    "                    hr.append(vals[:,3])\n",
    "                    rr.append(vals[:,4])\n",
    "\n",
    "                    # extract non-null values\n",
    "                    dbp[i] = dbp[i][~np.isnan(dbp[i])]  \n",
    "                    sbp[i] = sbp[i][~np.isnan(sbp[i])] \n",
    "                    bt[i] = bt[i][~np.isnan(bt[i])]\n",
    "                    hr[i] = hr[i][~np.isnan(hr[i])] \n",
    "                    rr[i] = rr[i][~np.isnan(rr[i])]\n",
    "\n",
    "                except Exception as e: \n",
    "                    print('\\n=================\\n')\n",
    "                    print('INDEX: '+str(i))\n",
    "                    print('ERROR: '+str(type(e)))\n",
    "                    print('\\n=================\\n')\n",
    "                    pass\n",
    "\n",
    "        if(type in ('a','w')):\n",
    "            for i in range(0,n_cases):\n",
    "                #vals = vitaldb.load_case(caseids[i], ['ECG_II'], 0.01) #parameter 0.01 for a 'zoomed' ecg\n",
    "                vals = vitaldb.load_case(caseids[i], ['ECG_II'])\n",
    "                ecg.append(vals[:,0])\n",
    "    \n",
    "    return ecg,dbp,sbp,bt,hr,rr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_ills_API(type='a',n_cases=None):\n",
    "    caseids_all = vitaldb.find_cases(['ECG_II','ART_DBP','ART_SBP','BT','HR','RR']) # find ids of patient with this parameters\n",
    "    # Load dataset\n",
    "    df = pd.read_csv('https://api.vitaldb.net/cases')\n",
    "    df = df[df['asa'] > 3]\n",
    "\n",
    "    caseids_unhealthy = df['caseid'].to_numpy() \n",
    "    caseids = [el for el in caseids_all if el in caseids_unhealthy]\n",
    "\n",
    "    if(n_cases is None):\n",
    "        n_cases = len(caseids)\n",
    "\n",
    "    ecg = []\n",
    "    dbp = []\n",
    "    sbp = []\n",
    "    bt  = []\n",
    "    hr  = []\n",
    "    rr  = []\n",
    "\n",
    "    if(type in ('a','n','w')):\n",
    "\n",
    "        if(type in ('a','n')):\n",
    "\n",
    "            # load all the patients data \n",
    "            for i in range(0,n_cases): # Select only five patient for testing purpose; then len(caseids)\n",
    "                try:\n",
    "                    vals = vitaldb.load_case(caseids[i], ['ART_DBP','ART_SBP','BT','HR','RR'])\n",
    "                    dbp.append(vals[:,0])\n",
    "                    sbp.append(vals[:,1])\n",
    "                    bt.append(vals[:,2])\n",
    "                    hr.append(vals[:,3])\n",
    "                    rr.append(vals[:,4])\n",
    "\n",
    "                    # extract non-null values\n",
    "                    dbp[i] = dbp[i][~np.isnan(dbp[i])]  \n",
    "                    sbp[i] = sbp[i][~np.isnan(sbp[i])] \n",
    "                    bt[i] = bt[i][~np.isnan(bt[i])]\n",
    "                    hr[i] = hr[i][~np.isnan(hr[i])] \n",
    "                    rr[i] = rr[i][~np.isnan(rr[i])]\n",
    "\n",
    "                except Exception as e: \n",
    "                    print('\\n=================\\n')\n",
    "                    print('INDEX: '+str(i))\n",
    "                    print('ERROR: '+str(type(e)))\n",
    "                    print('\\n=================\\n')\n",
    "                    pass\n",
    "\n",
    "        if(type in ('a','w')):\n",
    "            for i in range(0,n_cases):\n",
    "                #vals = vitaldb.load_case(caseids[i], ['ECG_II'], 0.01) #parameter 0.01 for a 'zoomed' ecg\n",
    "                vals = vitaldb.load_case(caseids[i], ['ECG_II'])\n",
    "                ecg.append(vals[:,0])\n",
    "    \n",
    "    return ecg,dbp,sbp,bt,hr,rr\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disk data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_disk(path):\n",
    "    \n",
    "    ecg = []\n",
    "    dbp = []\n",
    "    sbp = []\n",
    "    bt  = []\n",
    "    hr  = []\n",
    "    rr  = []\n",
    "\n",
    "# save the data into a file since loading all the 2k caseids requires at least 1h\n",
    "    filepath = os.path.join(path,'numeric_data.vitaldb')\n",
    "    ecgpath = os.path.join(path,'ecg_data.vitaldb')\n",
    "    #ecgpath = '/Volumes/Windows/SIIA/ecg_data.vitaldb'\n",
    "\n",
    "    with open(ecgpath, 'rb') as f:\n",
    "        (ecg) = pickle.load(f)\n",
    "    with open(filepath, 'rb') as f:\n",
    "        (dbp,sbp,bt,hr,rr) = pickle.load(f)\n",
    "    \n",
    "    return ecg,dbp,sbp,bt,hr,rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_disk(path,ecg,dbp,sbp,bt,hr,rr):\n",
    "# save the data into a file since loading all the 2k caseids requires at least 1h\n",
    "\n",
    "    with open(os.path.join(path,'numeric_data.vitaldb'), 'wb') as f:\n",
    "        pickle.dump((dbp,sbp,bt,hr,rr), f)\n",
    "\n",
    "    with open(os.path.join(path,'ecg_data.vitaldb'), 'wb') as f:\n",
    "        pickle.dump(ecg, f)\n",
    "\n",
    "\n",
    "\n",
    "## save the data into a file since loading all the 2k caseids requires at least 1h\n",
    "#filepath = '/Users/Roberto/projects/siiaproject-vitanomaly/data.vitaldb'\n",
    "#ecgpath = '/Volumes/Windows/SIIA/ecg_data.vitaldb'\n",
    "#ecgpath = '/Users/Roberto/projects/siiaproject-vitanomaly/ecg_data.vitaldb'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(ecg,dbp,sbp,bt,hr,rr,val = None):\n",
    "    \n",
    "    if(val == None or not isinstance(val,int)):\n",
    "        val = np.argmin(np.array([\n",
    "                         min([len(el) for el in ecg]),\n",
    "                         min([len(el) for el in dbp]),\n",
    "                         min([len(el) for el in sbp]),\n",
    "                         min([len(el) for el in  bt]),\n",
    "                         min([len(el) for el in  hr]),\n",
    "                         min([len(el) for el in  rr])]))\n",
    "        print(val)\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(611)\n",
    "    plt.title(\"ECG\")\n",
    "    for el in ecg:\n",
    "        plt.plot(el)\n",
    "    plt.subplots_adjust(hspace=1.)\n",
    "    plt.subplot(612)\n",
    "    plt.title(\"DBP\")\n",
    "    for el in dbp:\n",
    "        plt.plot(el, color='b')\n",
    "    plt.subplots_adjust(hspace=1.)\n",
    "    plt.subplot(613)\n",
    "    plt.title(\"SBP\")\n",
    "    for el in sbp:\n",
    "        plt.plot(el, color='r')\n",
    "\n",
    "    plt.subplot(614)\n",
    "    plt.title(\"Body temperature\")\n",
    "    for el in bt:\n",
    "        plt.plot(el, color='orange')\n",
    "\n",
    "    plt.subplot(615)\n",
    "    plt.title(\"Heart rate\")\n",
    "    for el in hr:\n",
    "        plt.plot(el, color='r')\n",
    "\n",
    "    plt.subplot(616)\n",
    "    plt.title(\"Respiratory rate\")\n",
    "    for el in rr:\n",
    "        plt.plot(el, color='g')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(ecg,dbp,sbp,bt,hr,rr):\n",
    "# remove empty or with negative mean time series \n",
    "\n",
    "    try:\n",
    "        for i in range(0,len(ecg) - len([el for el in ecg if len(el) == 0 or (np.mean(el) <= 0)])): \n",
    "            if(len(ecg[i])==0 or (np.mean(ecg[i]) <= 0)):\n",
    "                ecg.pop(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        for i in range(0,len(dbp) - len([el for el in dbp if len(el) == 0 or (np.mean(el) <= 0)])):\n",
    "            if(len(dbp[i])==0 or (np.mean(dbp[i]) <= 0)):\n",
    "                dbp.pop(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        for i in range(0,len(sbp) - len([el for el in sbp if len(el) == 0 or (np.mean(el) <= 0)])):\n",
    "            if(len(sbp[i])==0 or (np.mean(sbp[i]) <= 0)):\n",
    "                sbp.pop(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        for i in range(0,len(bt) - len([el for el in bt if len(el) == 0 or (np.mean(el) <= 0)])):\n",
    "            if(len(bt[i])==0 or (np.mean(bt[i]) <= 0)):\n",
    "                bt.pop(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        for i in range(0,len(hr) - len([el for el in hr if len(el) == 0 or (np.mean(el) <= 0)])):\n",
    "            if(len(hr[i])==0 or (np.mean(hr[i]) <= 0)):\n",
    "                hr.pop(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        for i in range(0,len(rr) - len([el for el in rr if len(el) == 0 or (np.mean(el) <= 0)])):\n",
    "            if(len(rr[i])==0 or (np.mean(rr[i]) <= 0)):\n",
    "                rr.pop(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return ecg,dbp,sbp,bt,hr,rr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mean_norm(ecg,dbp,sbp,bt,hr,rr):\n",
    "\n",
    "\n",
    "    flat_list_ecg = np.asarray([item for sublist in ecg for item in sublist],dtype='float64')\n",
    "    flat_list_dbp = np.asarray([item for sublist in dbp for item in sublist],dtype='float64')\n",
    "    flat_list_sbp = np.asarray([item for sublist in sbp for item in sublist],dtype='float64')\n",
    "    flat_list_hr = np.asarray([item for sublist in hr for item in sublist],dtype='float64')\n",
    "    flat_list_bt = np.asarray([item for sublist in bt  for item in sublist],dtype='float64')\n",
    "    flat_list_rr = np.asarray([item for sublist in rr for item in sublist],dtype='float64')\n",
    "    #print({'dbp':len(flat_list_dbp),'sbp':len(flat_list_sbp),'hr':len(flat_list_hr),'bt':len(flat_list_bt),'rr':len(flat_list_rr)})\n",
    "    print({'dbp':len(dbp),'sbp':len(sbp),'hr':len(hr),'bt':len(bt),'rr':len(rr)})\n",
    "\n",
    "\n",
    "    ecg_mean,ecg_std = np.mean(flat_list_ecg),np.std(flat_list_ecg)\n",
    "    dbp_mean,dbp_std = np.mean(flat_list_dbp),np.std(flat_list_dbp)\n",
    "    sbp_mean,sbp_std = np.mean(flat_list_sbp),np.std(flat_list_sbp)\n",
    "    bt_mean,bt_std = np.mean(flat_list_bt),np.std(flat_list_bt)\n",
    "    hr_mean,hr_std = np.mean(flat_list_hr),np.std(flat_list_hr)\n",
    "    rr_mean,rr_std = np.mean(flat_list_rr),np.std(flat_list_rr)\n",
    "\n",
    "    print('\\nMean values for features:')\n",
    "    print({'ecg':ecg_mean,'dbp':dbp_mean,'sbp':sbp_mean,'hr':hr_mean,'bt':bt_mean,'rr':rr_mean})\n",
    "    print('\\nStd values for features:')\n",
    "    print({'ecg':ecg_std,'dbp':dbp_std,'sbp':sbp_std,'hr':hr_std,'bt':bt_std,'rr':rr_std})\n",
    "    print('\\n')\n",
    "\n",
    "    # Consider runtime warnings such as Divide by zero as Exceptions to throw\n",
    "    old_settings = np.seterr(divide='raise')\n",
    "    idx_remove = {}\n",
    "    idx_remove['ecg'] = []\n",
    "    idx_remove['sbp'] = []\n",
    "    idx_remove['dbp'] = []\n",
    "    idx_remove['bt'] = []\n",
    "    idx_remove['rr'] = []\n",
    "    idx_remove['hr'] = []\n",
    "    \n",
    "\n",
    "    for i in range(0,len(ecg)): \n",
    "        try:\n",
    "            ecg[i][np.argwhere(ecg[i] < 0)] = np.mean(ecg[i])\n",
    "            ecg[i] = (ecg[i] - ecg_mean)/(ecg_std) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['ecg'].append(i)\n",
    "                \n",
    "\n",
    "    for i in range(0,len(dbp)): \n",
    "        try:\n",
    "            dbp[i][np.argwhere(dbp[i] <= 30)] = np.mean(dbp[i])\n",
    "            dbp[i] = (dbp[i] - dbp_mean)/(dbp_std) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['dbp'].append(i)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0,len(sbp)): \n",
    "        try:\n",
    "            sbp[i][np.argwhere(sbp[i] <= 70 )] = np.mean(sbp[i])\n",
    "            sbp[i] = (sbp[i] - sbp_mean)/(sbp_std) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['sbp'].append(i)\n",
    "        \n",
    "\n",
    "\n",
    "    for i in range(0,len(bt)): \n",
    "        try:\n",
    "            bt[i][np.argwhere(bt[i] <= 33)] = np.mean(bt[i])\n",
    "            bt[i] = (bt[i] - bt_mean)/(bt_std) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['bt'].append(i)\n",
    "\n",
    "\n",
    "    for i in range(0,len(hr)): \n",
    "        try:\n",
    "            hr[i][np.argwhere(hr[i] <= 35)] = np.mean(hr[i])\n",
    "            hr[i] = (hr[i] - hr_mean)/(hr_std) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['hr'].append(i)\n",
    "\n",
    "    for i in range(0,len(rr)): \n",
    "        try:\n",
    "            rr[i][np.argwhere(rr[i] <= 8)] = np.mean(rr[i])\n",
    "            rr[i] = (rr[i] - rr_mean)/(rr_std) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['hr'].append(i)\n",
    "\n",
    "    # Back to default settings for errors\n",
    "    np.seterr(**old_settings)\n",
    "\n",
    "    return ecg,dbp,sbp,bt,hr,rr,idx_remove\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def minmax_norm(ecg,dbp,sbp,bt,hr,rr):\n",
    "\n",
    "\n",
    "    flat_list_ecg = np.asarray([item for sublist in ecg for item in sublist],dtype='float64')\n",
    "    flat_list_dbp = np.asarray([item for sublist in dbp for item in sublist],dtype='float64')\n",
    "    flat_list_sbp = np.asarray([item for sublist in sbp for item in sublist],dtype='float64')\n",
    "    flat_list_hr = np.asarray([item for sublist in hr for item in sublist],dtype='float64')\n",
    "    flat_list_bt = np.asarray([item for sublist in bt  for item in sublist],dtype='float64')\n",
    "    flat_list_rr = np.asarray([item for sublist in rr for item in sublist],dtype='float64')\n",
    "    #print({'dbp':len(flat_list_dbp),'sbp':len(flat_list_sbp),'hr':len(flat_list_hr),'bt':len(flat_list_bt),'rr':len(flat_list_rr)})\n",
    "\n",
    "\n",
    "    ecg_min,ecg_max = np.min(flat_list_ecg),np.max(flat_list_ecg)\n",
    "    dbp_min,dbp_max = np.min(flat_list_dbp),np.max(flat_list_dbp)\n",
    "    sbp_min,sbp_max = np.min(flat_list_sbp),np.max(flat_list_sbp)\n",
    "    bt_min,bt_max = np.min(flat_list_bt),np.max(flat_list_bt)\n",
    "    hr_min,hr_max = np.min(flat_list_hr),np.max(flat_list_hr)\n",
    "    rr_min,rr_max = np.min(flat_list_rr),np.max(flat_list_rr)\n",
    "    \n",
    "    old_settings = np.seterr(divide='raise')\n",
    "    idx_remove = {}\n",
    "    idx_remove['ecg'] = []\n",
    "    idx_remove['sbp'] = []\n",
    "    idx_remove['dbp'] = []\n",
    "    idx_remove['bt'] = []\n",
    "    idx_remove['rr'] = []\n",
    "    idx_remove['hr'] = []\n",
    "\n",
    "    for i in range(0,len(ecg)): \n",
    "        try:\n",
    "            ecg[i][np.argwhere(ecg[i]<0)] = np.mean(ecg[i])\n",
    "            ecg[i] = (ecg[i] - ecg_min)/(ecg_max - ecg_min) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['ecg'].append(i)\n",
    "\n",
    "\n",
    "    for i in range(0,len(dbp)): \n",
    "        try:\n",
    "            dbp[i][np.argwhere(dbp[i]<=30)] = np.mean(dbp[i])\n",
    "            dbp[i] = (dbp[i] - dbp_min)/(dbp_max - dbp_min) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['dbp'].append(i)\n",
    "\n",
    "\n",
    "    for i in range(0,len(sbp)): \n",
    "        try:\n",
    "            sbp[i][np.argwhere(sbp[i] <= 70)] = np.mean(sbp[i])\n",
    "            sbp[i] = (sbp[i] - sbp_min)/(sbp_max - sbp_min) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['sbp'].append(i)\n",
    "\n",
    "\n",
    "    for i in range(0,len(bt)): \n",
    "        try:\n",
    "            bt[i][np.argwhere(bt[i]<=33)] = np.mean(bt[i])\n",
    "            bt[i] = (bt[i] - bt_min)/(bt_max - bt_min) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['bt'].append(i)\n",
    "\n",
    "\n",
    "    for i in range(0,len(hr)): \n",
    "        try:\n",
    "            hr[i][np.argwhere(hr[i]<=35)] = np.mean(hr[i])\n",
    "            hr[i] = (hr[i] - hr_min)/(hr_max - hr_min) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['hr'].append(i)\n",
    "\n",
    "\n",
    "    for i in range(0,len(rr)): \n",
    "        try:\n",
    "            rr[i][np.argwhere(rr[i]<=8)] = np.mean(rr[i])\n",
    "            rr[i] = (rr[i] - rr_min)/(rr_max - rr_min) \n",
    "        except: \n",
    "            # remove values for which the normalization gives Runtime warning\n",
    "            idx_remove['rr'].append(i)\n",
    "\n",
    "\n",
    "    # Back to default settings for errors\n",
    "    np.seterr(**old_settings)\n",
    "\n",
    "    return ecg,dbp,sbp,bt,hr,rr,idx_remove\n",
    "\n",
    "\n",
    "\n",
    "def get_preprocessed_data(path, norm_func = None):\n",
    "\n",
    "    ecg,dbp,sbp,bt,hr,rr = load_from_disk(path=path)\n",
    "    ecg,dbp,sbp,bt,hr,rr = clean_data(ecg,dbp,sbp,bt,hr,rr)\n",
    "\n",
    "    if(norm_func is not None):\n",
    "        ecg,dbp,sbp,bt,hr,rr,idx_remove = norm_func(ecg,dbp,sbp,bt,hr,rr)\n",
    "        \n",
    "    idx_remove = []\n",
    "    return ecg,dbp,sbp,bt,hr,rr,idx_remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/Roberto/projects/AnomalyDetection/data/processed'\n",
    "norm = 'minmax'\n",
    "func_norm = norm + '_norm'\n",
    "normalize = globals()[func_norm] # normalize is called later for test data normalization\n",
    "\n",
    "ecg,dbp,sbp,bt,hr,rr,idx_remove = get_preprocessed_data(path = path,norm_func = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Autoencoder\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ecg,dbp,sbp,bt,hr,rr, TIME_STEP = 7000, n_instances = None):\n",
    "\n",
    "    flat_list_ecg = np.asarray([item for sublist in ecg for item in sublist],dtype='float64')\n",
    "    flat_list_dbp = np.asarray([item for sublist in dbp for item in sublist],dtype='float64')\n",
    "    flat_list_sbp = np.asarray([item for sublist in sbp for item in sublist],dtype='float64')\n",
    "    flat_list_bt = np.asarray([item for sublist in bt for item in sublist],dtype='float64')\n",
    "    flat_list_hr = np.asarray([item for sublist in hr for item in sublist],dtype='float64')\n",
    "    flat_list_rr = np.asarray([item for sublist in rr for item in sublist],dtype='float64')\n",
    "    #print({'ecg': len(flat_list_ecg),'dbp':len(flat_list_dbp),'sbp':len(flat_list_sbp),'hr':len(flat_list_hr),'bt':len(flat_list_bt),'rr':len(flat_list_rr)})\n",
    "\n",
    "\n",
    "    X_ecg = []\n",
    "    X_dbp = []\n",
    "    X_sbp = []\n",
    "    X_bt = []\n",
    "    X_hr = []\n",
    "    X_rr = []\n",
    "\n",
    "    for seq in range(0,len(flat_list_ecg), TIME_STEP):\n",
    "        X_ecg.append(flat_list_ecg[seq:seq+TIME_STEP])\n",
    "\n",
    "    for seq in range(0,len(flat_list_dbp), TIME_STEP):\n",
    "        X_dbp.append(flat_list_dbp[seq:seq+TIME_STEP])\n",
    "\n",
    "    for seq in range(0,len(flat_list_sbp), TIME_STEP):\n",
    "        X_sbp.append(flat_list_sbp[seq:seq+TIME_STEP])\n",
    "\n",
    "    for seq in range(0,len(flat_list_bt), TIME_STEP):\n",
    "        X_bt.append(flat_list_bt[seq:seq+TIME_STEP])\n",
    "\n",
    "    for seq in range(0,len(flat_list_hr), TIME_STEP):\n",
    "        X_hr.append(flat_list_hr[seq:seq+TIME_STEP])\n",
    "\n",
    "    for seq in range(0,len(flat_list_rr), TIME_STEP):\n",
    "        X_rr.append(flat_list_rr[seq:seq+TIME_STEP])\n",
    "\n",
    "    X_ecg = np.asarray(X_ecg,dtype=object)\n",
    "    X_dbp = np.asarray(X_dbp,dtype=object)\n",
    "    X_sbp = np.asarray(X_sbp,dtype=object)\n",
    "    X_bt = np.asarray(X_bt,dtype=object)\n",
    "    X_hr = np.asarray(X_hr,dtype=object)\n",
    "    X_rr = np.asarray(X_rr,dtype=object)\n",
    "\n",
    "\n",
    "    X_ecg = pad_sequences(X_ecg, TIME_STEP,padding='post',value = np.mean(flat_list_ecg),dtype='float64')\n",
    "    X_dbp = pad_sequences(X_dbp, TIME_STEP,padding='post',value = np.mean(flat_list_dbp),dtype='float64')\n",
    "    X_sbp = pad_sequences(X_sbp, TIME_STEP,padding='post',value = np.mean(flat_list_sbp),dtype='float64')\n",
    "    X_bt = pad_sequences(X_bt, TIME_STEP,padding='post',value = np.mean(flat_list_bt),dtype='float64')\n",
    "    X_hr = pad_sequences(X_hr, TIME_STEP,padding='post',value = np.mean(flat_list_hr),dtype='float64')\n",
    "    X_rr = pad_sequences(X_rr, TIME_STEP,padding='post',value = np.mean(flat_list_rr),dtype='float64')\n",
    "\n",
    "\n",
    "    X_ecg = np.asarray(np.expand_dims(X_ecg,axis=2))\n",
    "    X_dbp = np.asarray(np.expand_dims(X_dbp,axis=2))\n",
    "    X_sbp = np.asarray(np.expand_dims(X_sbp,axis=2))\n",
    "    X_bt = np.asarray(np.expand_dims(X_bt,axis=2))\n",
    "    X_hr = np.asarray(np.expand_dims(X_hr,axis=2))\n",
    "    X_rr = np.asarray(np.expand_dims(X_rr,axis=2))\n",
    "\n",
    "\n",
    "    min_len = np.min([X_dbp.shape[0],X_sbp.shape[0],X_bt.shape[0],X_hr.shape[0],X_rr.shape[0]])\n",
    "    \n",
    "    X_ecg = X_ecg[:min_len,:]\n",
    "    X_dbp = X_dbp[:min_len,:]\n",
    "    X_sbp = X_sbp[:min_len,:]\n",
    "    X_bt = X_bt[:min_len,:]\n",
    "    X_hr = X_hr[:min_len,:]\n",
    "    X_rr = X_rr[:min_len,:]\n",
    "\n",
    "    Y = np.concatenate([X_dbp, X_sbp, X_bt, X_hr, X_rr],axis=2)\n",
    "    \n",
    "    if(isinstance(n_instances,int) and n_instances > 0):\n",
    "        X = Y[:n_instances] # Select the first n instances\n",
    "    else:\n",
    "        X = Y\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def eval_error(X_test,res,full = False):\n",
    "    \n",
    "    for p in range(0,X_test.shape[0]):\n",
    "        # Print the reconstruction error for all the features of a given test instance\n",
    "        #print('=======================================')\n",
    "        print('\\tTest instance ' + str(p))\n",
    "        #print('======================================='+'\\n')\n",
    "        tot = 0\n",
    "        for i in range(0,5):\n",
    "            re = np.round(abs(np.linalg.norm(res[p,:,i]) - np.linalg.norm(X_test[p,:,i],2)),3)\n",
    "            tot = tot + re\n",
    "            if(full == True):\n",
    "                print('Reconstrucion error on feature ' + str(i) + ': ' + \\\n",
    "                      str(re)+'\\n')\n",
    "        print('Mean reconstruction error: ' + str(np.round(tot/5,3)))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess(ecg,dbp,sbp,bt,hr,rr,n_instances = 50)\n",
    "batch_size, seq_len, n_features = X_train.shape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(seq_len, n_features),return_sequences=True))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, X_train, epochs=5,shuffle=False,verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cases = 10\n",
    "\n",
    "nhecg,nhdbp,nhsbp,nhbt,nhhr,nhrr = load_ills_API(n_cases=n_cases)\n",
    "hecg,hdbp,hsbp,hbt,hhr,hrr = load_healthy_API(n_cases=n_cases)\n",
    "\n",
    "nhecg,nhdbp,nhsbp,nhbt,nhhr,nhrr = clean_data(nhecg,nhdbp,nhsbp,nhbt,nhhr,nhrr)\n",
    "nhecg,nhdbp,nhsbp,nhbt,nhhr,nhrr,_ = normalize(nhecg,nhdbp,nhsbp,nhbt,nhhr,nhrr)\n",
    "\n",
    "hecg,hdbp,hsbp,hbt,hhr,hrr = clean_data(hecg,hdbp,hsbp,hbt,hhr,hrr)\n",
    "hecg,hdbp,hsbp,hbt,hhr,hrr,_ = normalize(hecg,hdbp,hsbp,hbt,hhr,hrr) # normalize the test instance with the same approach of train ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_nh = preprocess(nhecg,nhdbp,nhsbp,nhbt,nhhr,nhrr)\n",
    "X_test_h = preprocess(hecg,hdbp,hsbp,hbt,hhr,hrr)\n",
    "\n",
    "res_nh = model.predict(X_test_nh)\n",
    "res_h = model.predict(X_test_h)\n",
    "\n",
    "print(X_test_h.shape,X_test_nh.shape)\n",
    "\n",
    "#n_feature = 1\n",
    "#abs(np.linalg.norm(res[...,n_feature]) - np.linalg.norm(X_test[...,n_feature],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HEALTHY PATIENTS\n",
      "\n",
      "\tTest instance 0\n",
      "Reconstrucion error on feature 0: 12.026\n",
      "\n",
      "Reconstrucion error on feature 1: 9.164\n",
      "\n",
      "Reconstrucion error on feature 2: 0.368\n",
      "\n",
      "Reconstrucion error on feature 3: 20.749\n",
      "\n",
      "Reconstrucion error on feature 4: 0.705\n",
      "\n",
      "Mean reconstruction error: 8.602\n",
      "\n",
      "\n",
      "\tTest instance 1\n",
      "Reconstrucion error on feature 0: 13.173\n",
      "\n",
      "Reconstrucion error on feature 1: 13.181\n",
      "\n",
      "Reconstrucion error on feature 2: 0.175\n",
      "\n",
      "Reconstrucion error on feature 3: 19.368\n",
      "\n",
      "Reconstrucion error on feature 4: 2.022\n",
      "\n",
      "Mean reconstruction error: 9.584\n",
      "\n",
      "\n",
      "\tTest instance 2\n",
      "Reconstrucion error on feature 0: 11.863\n",
      "\n",
      "Reconstrucion error on feature 1: 10.394\n",
      "\n",
      "Reconstrucion error on feature 2: 1.157\n",
      "\n",
      "Reconstrucion error on feature 3: 20.537\n",
      "\n",
      "Reconstrucion error on feature 4: 2.772\n",
      "\n",
      "Mean reconstruction error: 9.345\n",
      "\n",
      "\n",
      "\tTest instance 3\n",
      "Reconstrucion error on feature 0: 10.905\n",
      "\n",
      "Reconstrucion error on feature 1: 11.214\n",
      "\n",
      "Reconstrucion error on feature 2: 0.297\n",
      "\n",
      "Reconstrucion error on feature 3: 17.864\n",
      "\n",
      "Reconstrucion error on feature 4: 0.483\n",
      "\n",
      "Mean reconstruction error: 8.153\n",
      "\n",
      "\n",
      "\tTest instance 4\n",
      "Reconstrucion error on feature 0: 11.686\n",
      "\n",
      "Reconstrucion error on feature 1: 9.798\n",
      "\n",
      "Reconstrucion error on feature 2: 0.416\n",
      "\n",
      "Reconstrucion error on feature 3: 17.437\n",
      "\n",
      "Reconstrucion error on feature 4: 2.44\n",
      "\n",
      "Mean reconstruction error: 8.355\n",
      "\n",
      "\n",
      "\tTest instance 5\n",
      "Reconstrucion error on feature 0: 12.717\n",
      "\n",
      "Reconstrucion error on feature 1: 11.97\n",
      "\n",
      "Reconstrucion error on feature 2: 0.041\n",
      "\n",
      "Reconstrucion error on feature 3: 19.447\n",
      "\n",
      "Reconstrucion error on feature 4: 0.957\n",
      "\n",
      "Mean reconstruction error: 9.026\n",
      "\n",
      "\n",
      "\tTest instance 6\n",
      "Reconstrucion error on feature 0: 14.067\n",
      "\n",
      "Reconstrucion error on feature 1: 11.67\n",
      "\n",
      "Reconstrucion error on feature 2: 2.049\n",
      "\n",
      "Reconstrucion error on feature 3: 19.555\n",
      "\n",
      "Reconstrucion error on feature 4: 2.128\n",
      "\n",
      "Mean reconstruction error: 9.894\n",
      "\n",
      "\n",
      "\tTest instance 7\n",
      "Reconstrucion error on feature 0: 14.723\n",
      "\n",
      "Reconstrucion error on feature 1: 12.292\n",
      "\n",
      "Reconstrucion error on feature 2: 2.883\n",
      "\n",
      "Reconstrucion error on feature 3: 21.481\n",
      "\n",
      "Reconstrucion error on feature 4: 1.553\n",
      "\n",
      "Mean reconstruction error: 10.586\n",
      "\n",
      "\n",
      "\tTest instance 8\n",
      "Reconstrucion error on feature 0: 14.641\n",
      "\n",
      "Reconstrucion error on feature 1: 13.32\n",
      "\n",
      "Reconstrucion error on feature 2: 3.467\n",
      "\n",
      "Reconstrucion error on feature 3: 24.742\n",
      "\n",
      "Reconstrucion error on feature 4: 1.612\n",
      "\n",
      "Mean reconstruction error: 11.556\n",
      "\n",
      "\n",
      "\tTest instance 9\n",
      "Reconstrucion error on feature 0: 13.381\n",
      "\n",
      "Reconstrucion error on feature 1: 13.21\n",
      "\n",
      "Reconstrucion error on feature 2: 1.842\n",
      "\n",
      "Reconstrucion error on feature 3: 21.312\n",
      "\n",
      "Reconstrucion error on feature 4: 2.026\n",
      "\n",
      "Mean reconstruction error: 10.354\n",
      "\n",
      "\n",
      "\n",
      "ILL PATIENTS\n",
      "\n",
      "\tTest instance 0\n",
      "Reconstrucion error on feature 0: 12.4\n",
      "\n",
      "Reconstrucion error on feature 1: 14.612\n",
      "\n",
      "Reconstrucion error on feature 2: 10.818\n",
      "\n",
      "Reconstrucion error on feature 3: 42.263\n",
      "\n",
      "Reconstrucion error on feature 4: 30.061\n",
      "\n",
      "Mean reconstruction error: 22.031\n",
      "\n",
      "\n",
      "\tTest instance 1\n",
      "Reconstrucion error on feature 0: 10.743\n",
      "\n",
      "Reconstrucion error on feature 1: 16.139\n",
      "\n",
      "Reconstrucion error on feature 2: 15.001\n",
      "\n",
      "Reconstrucion error on feature 3: 51.099\n",
      "\n",
      "Reconstrucion error on feature 4: 29.215\n",
      "\n",
      "Mean reconstruction error: 24.439\n",
      "\n",
      "\n",
      "\tTest instance 2\n",
      "Reconstrucion error on feature 0: 13.588\n",
      "\n",
      "Reconstrucion error on feature 1: 12.886\n",
      "\n",
      "Reconstrucion error on feature 2: 10.544\n",
      "\n",
      "Reconstrucion error on feature 3: 47.879\n",
      "\n",
      "Reconstrucion error on feature 4: 26.573\n",
      "\n",
      "Mean reconstruction error: 22.294\n",
      "\n",
      "\n",
      "\tTest instance 3\n",
      "Reconstrucion error on feature 0: 10.575\n",
      "\n",
      "Reconstrucion error on feature 1: 11.17\n",
      "\n",
      "Reconstrucion error on feature 2: 12.063\n",
      "\n",
      "Reconstrucion error on feature 3: 37.16\n",
      "\n",
      "Reconstrucion error on feature 4: 27.094\n",
      "\n",
      "Mean reconstruction error: 19.612\n",
      "\n",
      "\n",
      "\tTest instance 4\n",
      "Reconstrucion error on feature 0: 10.429\n",
      "\n",
      "Reconstrucion error on feature 1: 9.739\n",
      "\n",
      "Reconstrucion error on feature 2: 7.904\n",
      "\n",
      "Reconstrucion error on feature 3: 29.338\n",
      "\n",
      "Reconstrucion error on feature 4: 23.6\n",
      "\n",
      "Mean reconstruction error: 16.202\n",
      "\n",
      "\n",
      "\tTest instance 5\n",
      "Reconstrucion error on feature 0: 12.159\n",
      "\n",
      "Reconstrucion error on feature 1: 11.826\n",
      "\n",
      "Reconstrucion error on feature 2: 7.174\n",
      "\n",
      "Reconstrucion error on feature 3: 30.643\n",
      "\n",
      "Reconstrucion error on feature 4: 20.199\n",
      "\n",
      "Mean reconstruction error: 16.4\n",
      "\n",
      "\n",
      "\tTest instance 6\n",
      "Reconstrucion error on feature 0: 11.587\n",
      "\n",
      "Reconstrucion error on feature 1: 9.681\n",
      "\n",
      "Reconstrucion error on feature 2: 6.161\n",
      "\n",
      "Reconstrucion error on feature 3: 25.086\n",
      "\n",
      "Reconstrucion error on feature 4: 23.238\n",
      "\n",
      "Mean reconstruction error: 15.151\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nHEALTHY PATIENTS\\n')\n",
    "eval_error(X_test_h,res_h,True)\n",
    "print('\\nILL PATIENTS\\n')\n",
    "eval_error(X_test_nh,res_nh,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#p = 0 # test instance\n",
    "#\n",
    "#plt.figure(figsize=(20,10))\n",
    "#for i in range(0,5):\n",
    "#    s = '51'+str(i+1)\n",
    "#    plt.subplot(int(s))\n",
    "#    plt.subplots_adjust(hspace=1.)\n",
    "#    plt.title('Feature ' + str(i+1))\n",
    "#    plt.plot(res_h[p,:,i],'-r',X_test_h[p,:,i],'-g', linewidth=2.5)\n",
    "#\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot all the feature data\n",
    "\n",
    "#plt.figure(figsize=(20,10))\n",
    "#plt.subplot(211)\n",
    "#plt.plot(res[...,1])\n",
    "#plt.subplot(212)\n",
    "#plt.plot(X_test[...,1])\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f3cce98b4a0628e00255681f870890cb90ecb6f8db2750deab685955efac63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
