{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vitaldb\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API data load and save on disk\n",
    "\n",
    "Load and save the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read healthy patients data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseids_all = vitaldb.find_cases(['ECG_II','ART_DBP','ART_SBP','BT','HR','RR']) # find ids of patient with this parameters\n",
    "# Load dataset\n",
    "df = pd.read_csv('https://api.vitaldb.net/cases')\n",
    "df = df[df['asa'] < 3] # Extract ids of patients with asa < 3 and not dead in hospital\n",
    "df = df[df['death_inhosp'] == False]\n",
    "\n",
    "caseids_healthy = df['caseid'].to_numpy() # extract the case ids of patience with good health\n",
    "caseids = [el for el in caseids_all if el in caseids_healthy]\n",
    "print(len(caseids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg = []\n",
    "dbp = []\n",
    "sbp = []\n",
    "bt  = []\n",
    "hr  = []\n",
    "rr  = []\n",
    "# load all the patients data \n",
    "for i in range(0,len(caseids)): # Select only five patient for testing purpose; then len(caseids)\n",
    "    try:\n",
    "        vals = vitaldb.load_case(caseids[i], ['ART_DBP','ART_SBP','BT','HR','RR'])\n",
    "        dbp.append(vals[:,0])\n",
    "        sbp.append(vals[:,1])\n",
    "        bt.append(vals[:,2])\n",
    "        hr.append(vals[:,3])\n",
    "        rr.append(vals[:,4])\n",
    "\n",
    "        # extract non-null values\n",
    "        dbp[i] = dbp[i][~np.isnan(dbp[i])]  \n",
    "        sbp[i] = sbp[i][~np.isnan(sbp[i])] \n",
    "        bt[i] = bt[i][~np.isnan(bt[i])]\n",
    "        hr[i] = hr[i][~np.isnan(hr[i])] \n",
    "        rr[i] = rr[i][~np.isnan(rr[i])]\n",
    "    \n",
    "    except Exception as e: \n",
    "        print('\\n=================\\n')\n",
    "        print('INDEX: '+str(i))\n",
    "        print('ERROR: '+str(type(e)))\n",
    "        print('\\n=================\\n')\n",
    "        pass\n",
    "\n",
    "\n",
    "for i in range(0,len(caseids)):\n",
    "    #vals = vitaldb.load_case(caseids[i], ['ECG_II'], 0.01) #parameter 0.01 for a 'zoomed' ecg\n",
    "    vals = vitaldb.load_case(caseids[i], ['ECG_II'])\n",
    "    ecg.append(vals[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into a file since loading all the 2k caseids requires at least 1h\n",
    "filepath = '/Users/Roberto/projects/siiaproject-vitanomaly/data.vitaldb'\n",
    "ecgpath = '/Volumes/Windows/SIIA/ecg_data.vitaldb'\n",
    "ecgpath = '/Users/Roberto/projects/siiaproject-vitanomaly/ecg_data.vitaldb'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into a file since loading all the 2k caseids requires at least 1h\n",
    "\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump((dbp,sbp,bt,hr,rr), f)\n",
    "\n",
    "with open(ecgpath, 'wb') as f:\n",
    "    pickle.dump(ecg, f)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg = []\n",
    "dbp = []\n",
    "sbp = []\n",
    "bt  = []\n",
    "hr  = []\n",
    "rr  = []\n",
    "\n",
    "# save the data into a file since loading all the 2k caseids requires at least 1h\n",
    "filepath = '/Users/Roberto/projects/AnomalyDetection/data/raw/numeric_data.vitaldb'\n",
    "ecgpath = '/Volumes/Windows/SIIA/ecg_data.vitaldb'\n",
    "ecgpath = '/Users/Roberto/projects/AnomalyDetection/data/raw/ecg_data.vitaldb'\n",
    "\n",
    "with open(ecgpath, 'rb') as f:\n",
    "    (ecg) = pickle.load(f)\n",
    "with open(filepath, 'rb') as f:\n",
    "    (dbp,sbp,bt,hr,rr) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty elements\n",
    "\n",
    "for i in range(0,len(dbp) - len([el for el in dbp if len(el) == 0])):\n",
    "    if(len(dbp[i])==0):\n",
    "        dbp.pop(i)\n",
    "\n",
    "for i in range(0,len(sbp) - len([el for el in sbp if len(el) == 0])):\n",
    "    if(len(sbp[i])==0):\n",
    "        sbp.pop(i)\n",
    "\n",
    "for i in range(0,len(bt) - len([el for el in bt if len(el) == 0])):\n",
    "    if(len(bt[i])==0):\n",
    "        bt.pop(i)\n",
    "\n",
    "for i in range(0,len(hr) - len([el for el in hr if len(el) == 0])):\n",
    "    if(len(hr[i])==0):\n",
    "        hr.pop(i)\n",
    "\n",
    "for i in range(0,len(rr) - len([el for el in rr if len(el) == 0])):\n",
    "    if(len(rr[i])==0):\n",
    "        rr.pop(i)\n",
    "\n",
    "for i in range(0,len(ecg) - len([el for el in ecg if len(el) == 0])):\n",
    "    if(len(ecg[i])==0):\n",
    "        ecg.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists should have the same length i.e. len(caseids)\n",
    "# Normalization can be done with a keras layer from preprocessing library\n",
    "old_settings = np.seterr(all='raise')\n",
    "idx_remove = []\n",
    "for i in range(0,len(ecg)): \n",
    "    try:\n",
    "        #Remove negative values\n",
    "        ecg[i][np.argwhere(ecg[i]<0)] = np.mean(ecg[i]) \n",
    "        # MinMax normalization\n",
    "        ecg[i] = (ecg[i] - np.min(ecg[i]))/(np.max(ecg[i])-np.min(ecg[i])) \n",
    "    except: \n",
    "        # remove values for which the normalization gives Runtime warning\n",
    "        idx_remove.append(i)\n",
    "\n",
    "for idx in idx_remove: \n",
    "    ecg.pop(idx)\n",
    "\n",
    "idx_remove = []\n",
    "for i in range(0,len(dbp)): \n",
    "    try:\n",
    "        #Remove negative values\n",
    "        dbp[i][np.argwhere(dbp[i]<0)] = np.mean(dbp[i]) \n",
    "        # MinMax normalization\n",
    "        dbp[i] = (dbp[i] - np.min(dbp[i]))/(np.max(dbp[i])-np.min(dbp[i])) \n",
    "    except: \n",
    "        # remove values for which the normalization gives Runtime warning\n",
    "        idx_remove.append(i)\n",
    "\n",
    "for idx in idx_remove: \n",
    "    dbp.pop(idx)\n",
    "\n",
    "idx_remove = []  \n",
    "for i in range(0,len(sbp)): \n",
    "    try:\n",
    "        #Remove negative values\n",
    "        sbp[i][np.argwhere(sbp[i]<0)] = np.mean(sbp[i]) \n",
    "        # MinMax normalization\n",
    "        sbp[i] = (sbp[i] - np.min(sbp[i]))/(np.max(sbp[i])-np.min(sbp[i])) \n",
    "    except: \n",
    "        # remove values for which the normalization gives Runtime warning\n",
    "        idx_remove.append(i)\n",
    "\n",
    "for idx in idx_remove: \n",
    "    sbp.pop(idx)\n",
    "\n",
    "\n",
    "\n",
    "idx_remove = []\n",
    "for i in range(0,len(bt)): \n",
    "    try:\n",
    "        #Remove negative values\n",
    "        bt[i][np.argwhere(bt[i]<0)] = np.mean(bt[i]) \n",
    "        # MinMax normalization\n",
    "        bt[i] = (bt[i] - np.min(bt[i]))/(np.max(bt[i])-np.min(bt[i])) \n",
    "    except: \n",
    "        # remove values for which the normalization gives Runtime warning\n",
    "        idx_remove.append(i)\n",
    "\n",
    "for idx in idx_remove: \n",
    "    bt.pop(idx)\n",
    "\n",
    "\n",
    "\n",
    "idx_remove = []\n",
    "for i in range(0,len(hr)): \n",
    "    try:\n",
    "        #Remove negative values\n",
    "        hr[i][np.argwhere(hr[i]<0)] = np.mean(hr[i]) \n",
    "        # MinMax normalization\n",
    "        hr[i] = (hr[i] - np.min(hr[i]))/(np.max(hr[i])-np.min(hr[i])) \n",
    "    except: \n",
    "        # remove values for which the normalization gives Runtime warning\n",
    "        idx_remove.append(i)\n",
    "\n",
    "for idx in idx_remove: \n",
    "    hr.pop(idx)\n",
    "\n",
    "\n",
    "idx_remove = []\n",
    "for i in range(0,len(rr)): \n",
    "    try:\n",
    "        #Remove negative values\n",
    "        rr[i][np.argwhere(rr[i]<0)] = np.mean(rr[i]) \n",
    "        # MinMax normalization\n",
    "        rr[i] = (rr[i] - np.min(rr[i]))/(np.max(rr[i])-np.min(rr[i])) \n",
    "    except: \n",
    "        # remove values for which the normalization gives Runtime warning\n",
    "        idx_remove.append(i)\n",
    "\n",
    "for idx in idx_remove: \n",
    "    rr.pop(idx)\n",
    "\n",
    "\n",
    "# Back to default settings for errors\n",
    "np.seterr(**old_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.argmax([len(el) for el in sbp])\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(511)\n",
    "plt.title(\"DBP\")\n",
    "plt.plot(dbp[p], color='b')\n",
    "plt.subplots_adjust(hspace=1.)\n",
    "plt.subplot(512)\n",
    "plt.title(\"SBP\")\n",
    "plt.plot(sbp[p][:], color='r')\n",
    "\n",
    "plt.subplot(513)\n",
    "plt.title(\"Body temperature\")\n",
    "plt.plot(bt[p][:], color='orange')\n",
    "\n",
    "plt.subplot(514)\n",
    "plt.title(\"Heart rate\")\n",
    "plt.plot(hr[p][:], color='r')\n",
    "\n",
    "plt.subplot(515)\n",
    "plt.title(\"Respiratory rate\")\n",
    "plt.plot(rr[p][:], color='g')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = np.asarray([item for sublist in dbp for item in sublist],dtype='float64')\n",
    "chunks = np.array_split(flat_list,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = len(chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = int(len(chunks) * 0.7) # 70% percent of data fro training\n",
    "max_lenght = max([len(el) for el in chunks])\n",
    "# Uniform lenghts\n",
    "X_train = pad_sequences(chunks, max_lenght,padding='post',value=0.5,dtype='float64')\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = X_train.shape[1]\n",
    "#input Layer\n",
    "input_layer = tf.keras.layers.Input(shape=(n_dim,))\n",
    "#Encoder\n",
    "encoder = tf.keras.layers.Dense(512, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(0.0005))(input_layer)\n",
    "encoder=tf.keras.layers.Dropout(0.2)(encoder)\n",
    "encoder = tf.keras.layers.Dense(256, activation='tanh')(encoder)\n",
    "encoder = tf.keras.layers.Dense(128, activation='relu')(encoder)\n",
    "encoder = tf.keras.layers.Dense(64, activation='relu')(encoder)\n",
    "# Decoder\n",
    "decoder = tf.keras.layers.Dense(64, activation='relu')(encoder)\n",
    "decoder = tf.keras.layers.Dense(128, activation='relu')(decoder)\n",
    "decoder = tf.keras.layers.Dense(256, activation='tanh')(decoder)\n",
    "decoder=tf.keras.layers.Dropout(0.2)(decoder)\n",
    "decoder = tf.keras.layers.Dense(512, activation='tanh')(decoder)\n",
    "decoder = tf.keras.layers.Dense(n_dim, activation='tanh')(decoder)\n",
    "#Autoencoder\n",
    "autoencoder = tf.keras.Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train,X_train,epochs=15,batch_size=64,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4355,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 17666), found shape=(None, 4355)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m test \u001b[39m=\u001b[39m test[:seq_len]\n\u001b[1;32m      8\u001b[0m test \u001b[39m=\u001b[39m (test\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mmin(test))\u001b[39m/\u001b[39m(np\u001b[39m.\u001b[39mmax(test)\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mmin(test))\n\u001b[0;32m---> 11\u001b[0m res \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49mexpand_dims(test,axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(test,\u001b[39m2\u001b[39m))\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(res[\u001b[39m0\u001b[39m],\u001b[39m2\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/9q/vg5rvmpn2hv8_mc8vpz6y9x80000gp/T/__autograph_generated_fileomw3kgwa.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Roberto/opt/anaconda3/envs/siia/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 17666), found shape=(None, 4355)\n"
     ]
    }
   ],
   "source": [
    "val_p = vitaldb.load_case(263, ['ART_DBP','ART_SBP','BT','HR','RR'])\n",
    "test = val_p[:,0]\n",
    "\n",
    "test = test[~np.isnan(test)] \n",
    "\n",
    "print(np.shape(test))\n",
    "\n",
    "test = test[:seq_len]\n",
    "test = (test-np.min(test))/(np.max(test)-np.min(test))\n",
    "\n",
    "\n",
    "res = autoencoder.predict(np.expand_dims(test,axis=0))\n",
    "\n",
    "print(np.linalg.norm(test,2))\n",
    "print(np.linalg.norm(res[0],2))\n",
    "print(abs(np.linalg.norm(test,2)-np.linalg.norm(res[0],2)))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(211)\n",
    "plt.title('Original')\n",
    "plt.plot(test)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Reconstructed')\n",
    "\n",
    "plt.plot(res[0],scaley=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a patient. NB: the data has to be normalized with MinMax approach\n",
    "#val_p = vitaldb.load_case(17, ['ART_DBP','ART_SBP','BT','HR','RR'])\n",
    "#\n",
    "## Pre-processing: remove nan vals, normalize and padding\n",
    "#val_p = val_p[~np.isnan(val_p)]\n",
    "#val_p = (val_p-np.min(val_p))/(np.max(val_p)-np.min(val_p))\n",
    "#test = pad_sequences([val_p],max_lenght,padding='post',value=0.5,dtype='float64')\n",
    "#\n",
    "#res = autoencoder.predict(test)\n",
    "#\n",
    "## The error for case 464 (ill patient) is much greater than case 17 (healthy patient)\n",
    "#print(np.linalg.norm(test,2))\n",
    "#print(np.linalg.norm(res[0],2))\n",
    "#print(abs(np.linalg.norm(test,2)-np.linalg.norm(res[0],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read UNHEALTHY patients data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "caseids_all = vitaldb.find_cases(['ART_DBP','ART_SBP']) # find ids of patient with this parameters\n",
    "# Load dataset\n",
    "df = pd.read_csv('https://api.vitaldb.net/cases')\n",
    "df = df[df['asa'] > 3]\n",
    "# df = df[df['death_inhosp'] == False] \n",
    "\n",
    "caseids_unhealthy = df['caseid'].to_numpy() #extract the case ids of patience with good health\n",
    "\n",
    "caseids = [el for el in caseids_all if el in caseids_unhealthy]\n",
    "\n",
    "dbp = []\n",
    "sbp = []\n",
    "# load all the patients data into bp\n",
    "for i in range(0,5):\n",
    "    vals = vitaldb.load_case(caseids[i], ['ART_DBP','ART_SBP'])\n",
    "    dbp.append(vals[:,0])\n",
    "    sbp.append(vals[:,1])\n",
    "    dbp[i] = dbp[i][~np.isnan(dbp[i])] # extract non-null values of dyastolic pressure\n",
    "    sbp[i] = sbp[i][~np.isnan(sbp[i])] # extract non-null values of systolic pressure\n",
    "    sbp[i][np.argwhere(sbp[i]<0)] = np.mean(sbp[i]) # Threshold on 50 and then substitute with the mean value of the single patient data\n",
    "    dbp[i][np.argwhere(dbp[i]<0)] = np.mean(dbp[i]) # Threshold on 50 and then substitute with the mean value of the single patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(211)\n",
    "plt.plot(dbp[4][:], color='b')\n",
    "plt.subplot(212)\n",
    "plt.plot(sbp[4][:], color='r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f3cce98b4a0628e00255681f870890cb90ecb6f8db2750deab685955efac63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
